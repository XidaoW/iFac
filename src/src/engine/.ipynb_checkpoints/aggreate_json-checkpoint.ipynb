{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "'''\n",
    "Created on 2019/01/02\n",
    "\n",
    "@author: xidaowen\n",
    "'''\n",
    "\n",
    "import ntf\n",
    "from myutil.histogram import createHistogram\n",
    "from myutil.plotter import showFactorValue, showHistDistribution\n",
    "from myutil.ponpare.reader import readPonpareData\n",
    "from myutil.ponpare.converter import     digitizeHistoryFeatureValue, transformForHistogram\n",
    "import multiview.mvtsne as mvtsne\n",
    "from sklearn.utils.testing import assert_raises\n",
    "\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# from scipy.special import entr\n",
    "from scipy import spatial\n",
    "\n",
    "import sys\n",
    "import json\n",
    "# from pyspark import SparkConf, SparkContext\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "_log = logging.getLogger('JNTF')\n",
    "\n",
    "\n",
    "def showLabel(label):\n",
    "    for i1, lbl1 in enumerate(label):\n",
    "        print(\"label:[%d] ->\" % i1)\n",
    "        for lbl2 in lbl1:\n",
    "            print(lbl2 + \",\")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "class iFacData():\n",
    "    def __init__(self):\n",
    "        self.domain = \"\"\n",
    "        self.labels = []\n",
    "        self.base = 0\n",
    "        self.cur_base = 0\n",
    "        self.hist = None\n",
    "        \n",
    "    def readData(self, domain = \"nba\", columns = []):\n",
    "        \"\"\"\n",
    "        read in the data and create labels\n",
    "        \"\"\"\n",
    "        self.domain = domain\n",
    "        if self.domain == \"nba\":\n",
    "            shots = pd.read_csv(\"data/NBA_shots_201415.csv\")\n",
    "            shots = shots[['PLAYER_ID','PLAYER_NAME','TEAM_ID','TEAM_NAME','ZoneName','PERIOD','SHOT_ATTEMPTED_FLAG','SHOT_MADE_FLAG']]\n",
    "            shots.PERIOD[shots.PERIOD > 4] = 5\n",
    "            self.column = ['PERIOD','TEAM_NAME','ZoneName']\n",
    "            shots_group_data_attempted = shots.groupby(self.column)['SHOT_ATTEMPTED_FLAG'].sum()\n",
    "            shots_group_data_attempted1 = shots_group_data_attempted.unstack(fill_value=0).to_panel()\n",
    "            self.hist = shots_group_data_attempted1.fillna(0).values\n",
    "            for i in range(len(self.column)):\n",
    "                each_label = shots_group_data_attempted1.fillna(0).axes[i].tolist()\n",
    "                each_label = [str(each_one).replace('!', '').replace('(','').replace(')','').replace(' ','') for each_one in each_label]\n",
    "                self.labels.append(each_label)\n",
    "            \n",
    "        if self.domain == \"nbaplayer\":\n",
    "            top_cnt = 15\n",
    "            shots = pd.read_csv(\"data/NBA_shots_201415.csv\")\n",
    "            shots = shots[['PLAYER_ID','PLAYER_NAME','TEAM_ID','TEAM_NAME','ZoneName','PERIOD','SHOT_ATTEMPTED_FLAG','SHOT_MADE_FLAG']]\n",
    "            shots.PERIOD[shots.PERIOD > 4] = 5\n",
    "\n",
    "            self.column = ['PERIOD','PLAYER_NAME','ZoneName']\n",
    "\n",
    "            shots_total = shots.groupby(['PLAYER_NAME'])['SHOT_ATTEMPTED_FLAG'].sum()\n",
    "            top_players = list(shots_total.sort_values(ascending=False).iloc[:top_cnt].index)\n",
    "\n",
    "            shots = shots[shots.PLAYER_NAME.isin(top_players)]\n",
    "            shots_group_data_attempted = shots.groupby(self.column)['SHOT_ATTEMPTED_FLAG'].sum()\n",
    "            shots_group_data_made = shots.groupby(self.column)['SHOT_MADE_FLAG'].sum()\n",
    "            shots_group_data_attempted = shots_group_data_made.div(shots_group_data_attempted, level=0)\n",
    "            shots_group_data_attempted1 = shots_group_data_attempted.unstack(fill_value=0).to_panel()\n",
    "            self.hist = shots_group_data_attempted1.fillna(0).values\n",
    "\n",
    "            for i in range(len(self.column)):\n",
    "                each_label = shots_group_data_attempted1.fillna(0).axes[i].tolist()\n",
    "                each_label = [str(each_one).replace('!', '').replace('(','').replace(')','').replace(' ','') for each_one in each_label]\n",
    "                self.labels.append(each_label)\n",
    "\n",
    "        elif self.domain == \"policy\":\n",
    "            policy = pd.read_csv(\"data/policy_adoption.csv\")\n",
    "            policy['adoption'] = 1\n",
    "            policy = policy[policy.adopted_year >= 1970]\n",
    "            policy = policy[policy.subject_name != \"Unknown\"]            \n",
    "            self.column = ['subject_name', 'adopted_year', 'state_id']\n",
    "            policy_group = policy.groupby(self.column)['adoption'].sum()\n",
    "            policy_group1 = policy_group.unstack(fill_value=0).to_panel()\n",
    "            self.hist = policy_group1.fillna(0).values\n",
    "            for i in range(len(self.column)):\n",
    "                each_label = policy_group1.fillna(0).axes[i].tolist()\n",
    "                each_label = [str(each_one).replace('!', '').replace('(','').replace(')','').replace(' ','') for each_one in each_label]\n",
    "                self.labels.append(each_label)            \n",
    "\n",
    "        elif self.domain == \"picso\":\n",
    "            policy = pd.read_csv(\"data/picso.csv\", header=None)\n",
    "            columns = ['member', 'year', 'keyword', 'value']\n",
    "            policy.columns = columns\n",
    "            self.column = columns[:3]\n",
    "            policy_group = policy.groupby(self.column)['value'].sum()\n",
    "            policy_group1 = policy_group.unstack(fill_value=0).to_panel()\n",
    "            self.hist = policy_group1.fillna(0).values\n",
    "            for i in range(len(self.column)):\n",
    "                each_label = policy_group1.fillna(0).axes[i].tolist()\n",
    "                each_label = [str(each_one) for each_one in each_label]\n",
    "                self.labels.append(each_label)  \n",
    "                \n",
    "        elif self.domain == \"purchase\":\n",
    "            couponAreaTest, couponAreaTrain, couponDetailTrain,                 couponListTest, couponListTrain,                 couponVisitTrain, userList = readPonpareData(valuePrefixed=True)\n",
    "\n",
    "            # Convert to one-hot expression.\n",
    "            userList, couponListTrain, couponListTest =                 digitizeHistoryFeatureValue(userList,\n",
    "                                            couponListTrain,\n",
    "                                            couponListTest)\n",
    "            # Convert to histogram.\n",
    "            distribution = transformForHistogram(userList,\n",
    "                                                 couponDetailTrain,\n",
    "                                                 couponVisitTrain,\n",
    "                                                 couponListTrain,\n",
    "                                                 couponListTest,\n",
    "                                                 couponAreaTrain,\n",
    "                                                 couponAreaTest)\n",
    "            self.column = [\"SEX_ID\", \"GENRE_NAME\", \"LIST_PREF_NAME\",\"AGE\"]\n",
    "            self.hist, bins, label = createHistogram(distribution, self.column) \n",
    "            self.labels = [['00Male', '01Female'],\n",
    "                           ['00Gourmet', '01Este', '02Beauty', '03NailEye', '04HairSalon', \n",
    "                            '05HealthMedicalCare', '06Relaxation', '07Leisure', '08HotelInn',\n",
    "                            '09Lesson','10HomeDelivery','11GiftCard','12OtherCoupons'],\n",
    "                      ['00北海道', '01青森県', '02岩手県', '03宮城県', '04秋田県', '05山形県', '06福島県', '07茨城県', '08栃木県', '09群馬県', '10埼玉県', '11千葉県', \n",
    "                      '12東京都', '13神奈川県', '14新潟県', '15富山県', '16石川県', '17福井県', '18山梨県', '19長野県', '20岐阜県', '21静岡県', '22愛知県', '23三重県', \n",
    "                      '24滋賀県', '25京都府', '26大阪府', '27兵庫県', '28奈良県', '29和歌山県', '30鳥取県', '31島根県', '32岡山県', '33広島県', '34山口県', '35徳島県', \n",
    "                      '36香川県', '37愛媛県', '38高知県', '39福岡県', '40佐賀県', '41長崎県', '42熊本県', '43大分県', '44宮崎県', '45鹿児島県', '46沖縄県'],\n",
    "                      ['00under', '01-20', '02-25', '03-30', '04-35', '05-40', '06-45', '07-50', '08-55', '09-60', '10-65', '11-70', '12-75over'],\n",
    "                      ['00under', '01-100', '02-1000', '03-2000', '04-3000', '05-5000', '06-10000', '07-20000', '08-30000', '09-50000over\"']\n",
    "    \n",
    "                     ]            \n",
    "\n",
    "    def computeReconstructionError(self, ntfInstance, hist):    \n",
    "        \"\"\"\n",
    "        compute the reconstruction error\n",
    "        type ntfInstance: NTF:\n",
    "        type hist: np.array: tensor data\n",
    "        rtype error: float\n",
    "        \"\"\"\n",
    "        dstHist = ntfInstance.reconstruct()\n",
    "        srcHist = hist\n",
    "        diffHist = srcHist - dstHist\n",
    "        diffHistSum = np.sum(diffHist*diffHist)\n",
    "        srcHistSum = np.sum(srcHist*srcHist)\n",
    "        return diffHistSum/srcHistSum\n",
    "\n",
    "    def computeFit(self, ntfInstance, hist):\n",
    "        dstHist = ntfInstance.reconstruct()\n",
    "        mean_hist = np.full(hist.shape, np.mean(hist))\n",
    "        mean_hist_diff = (mean_hist - hist)\n",
    "        residual_hist = dstHist - hist\n",
    "        ss_total = np.sum(mean_hist_diff*mean_hist_diff)        \n",
    "        ss_res = np.sum(residual_hist*residual_hist)        \n",
    "        return 1 - ss_res*1. / ss_total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def getFitForRanks(self, bases, trials = 5):\n",
    "        \"\"\"\n",
    "        compute the factors given different ranks and different random initializations\n",
    "        type bases: int: max number of components\n",
    "        type trials: int: number of independent trials\n",
    "        \"\"\"\n",
    "\n",
    "        def pctnonzero(arr):\n",
    "            return (len(arr) - np.count_nonzero(arr))*1./len(arr)\n",
    "\n",
    "        def gini(arr):\n",
    "            # (Warning: This is a concise implementation, but it is O(n**2)\n",
    "            # in time and memory, where n = len(x).  *Don't* pass in huge\n",
    "            # samples!)\n",
    "            # Mean absolute difference\n",
    "            mad = np.abs(np.subtract.outer(arr, arr)).mean()\n",
    "            # Relative mean absolute difference\n",
    "            rmad = mad/np.mean(arr)\n",
    "            # Gini coefficient\n",
    "            g = 0.5 * rmad\n",
    "            return g        \n",
    "\n",
    "        def normalized_entropy(arr):            \n",
    "            return stats.entropy(arr) *1. / np.log(len(arr))\n",
    "\n",
    "        def theil(arr): \n",
    "            # natural logarithm is default\n",
    "            redundancy = np.log(len(arr)) - stats.entropy(arr)\n",
    "            # inequality = 1 - exp(-redundancy)\n",
    "            return redundancy\n",
    "\n",
    "\n",
    "\n",
    "        self.base = bases\n",
    "        self.trials = trials\n",
    "        self.all_trials = []\n",
    "        self.metrics = {\"error\":[None]*self.base, \n",
    "                        \"fit\":[None]*self.base, \n",
    "                        \"stability\": [None]*self.base, \n",
    "                        \"entropy\": [None]*self.base, \n",
    "                        \"normalized_entropy\": [None]*self.base, \n",
    "                        \"pctnonzeros\": [None]*self.base, \n",
    "                        \"gini\": [None]*self.base, \n",
    "                        \"theil\": [None]*self.base, \n",
    "                        \"min_error_index\": [None]*self.base}\n",
    "        \n",
    "        self.weights_all = [None]*self.base\n",
    "        self.factors_all = [None]*self.base\n",
    "\n",
    "        conf = SparkConf().set(\"spark.driver.maxResultSize\", \"220g\").setAppName(\"DSGD_NTF\")\n",
    "        self.sc = SparkContext(conf=conf)\n",
    "        # def getNTF(random_seed, base_cnt, hist):\n",
    "        #   ntfInstance = ntf.NTF(base_cnt, hist, parallelCalc=True, ones = False, random_seed = random_seed)\n",
    "        #   ntfInstance.factorize(hist, showProgress=True)\n",
    "        #   # print(ntfInstance.factor)\n",
    "        #   return ntfInstance\n",
    "\n",
    "        # self.start_index = 2\n",
    "        for self.base_cnt in range(self.start_index, self.base+1):\n",
    "            try:\n",
    "                _log.info(\"Current Rank: {}\".format(self.base_cnt))\n",
    "                each_rank_trials = []\n",
    "                for random_seed in range(self.trials):\n",
    "                    _log.info(\"Current Trial: {}\".format(random_seed))\n",
    "                    ntfInstance = ntf.NTF(self.base_cnt, self.hist, parallelCalc=True, ones = False, random_seed = random_seed)\n",
    "                    ntfInstance.factorize(self.hist, showProgress=True)\n",
    "                    each_rank_trials.append(ntfInstance)\n",
    "\n",
    "                self.all_trials.append(each_rank_trials)\n",
    "                _log.info(\"Getting Metric for rank: {}\".format(self.base_cnt))\n",
    "                self.metrics[\"error\"][self.base_cnt-self.start_index] = []\n",
    "                self.metrics[\"fit\"][self.base_cnt-self.start_index] = []\n",
    "                self.metrics[\"stability\"][self.base_cnt-self.start_index] = []\n",
    "                self.metrics[\"entropy\"][self.base_cnt-self.start_index] = []            \n",
    "                self.metrics[\"normalized_entropy\"][self.base_cnt-self.start_index] = []\n",
    "                self.metrics[\"gini\"][self.base_cnt-self.start_index] = []            \n",
    "                self.metrics[\"theil\"][self.base_cnt-self.start_index] = []            \n",
    "                self.metrics[\"pctnonzeros\"][self.base_cnt-self.start_index] = []\n",
    "                self.weights_all[self.base_cnt-self.start_index] = []\n",
    "                self.factors_all[self.base_cnt-self.start_index] = []            \n",
    "                for random_seed in range(self.trials):\n",
    "                    _log.info(\"Getting Metric for Trial: {}\".format(random_seed))               \n",
    "                    ntfInstance = self.all_trials[self.base_cnt-self.start_index][random_seed]            \n",
    "                    self.metrics[\"error\"][self.base_cnt-self.start_index].append(self.computeReconstructionError(ntfInstance,self.hist))\n",
    "                    self.metrics[\"fit\"][self.base_cnt-self.start_index].append(self.computeFit(ntfInstance,self.hist))\n",
    "                    weights, factors = ntfInstance.getNormalizedFactor()\n",
    "                    self.weights_all[self.base_cnt-self.start_index].append(weights)\n",
    "                    self.factors_all[self.base_cnt-self.start_index].append(factors)\n",
    "                    self.metrics[\"entropy\"][self.base_cnt-self.start_index].append(np.mean([stats.entropy(factors[i][j]) for i in range(len(factors)) for j in range(len(factors[0]))]))\n",
    "                    self.metrics[\"normalized_entropy\"][self.base_cnt-self.start_index].append(np.mean([normalized_entropy(factors[i][j]) for i in range(len(factors)) for j in range(len(factors[0]))]))                \n",
    "                    self.metrics[\"pctnonzeros\"][self.base_cnt-self.start_index].append(np.mean([pctnonzero(factors[i][j]) for i in range(len(factors)) for j in range(len(factors[0]))]))\n",
    "                    self.metrics[\"theil\"][self.base_cnt-self.start_index].append(np.mean([theil(factors[i][j]) for i in range(len(factors)) for j in range(len(factors[0]))]))\n",
    "                    self.metrics[\"gini\"][self.base_cnt-self.start_index].append(np.mean([gini(factors[i][j]) for i in range(len(factors)) for j in range(len(factors[0]))]))\n",
    "                    \n",
    "\n",
    "                best_fit_index = np.argmin(self.metrics[\"error\"][self.base_cnt-self.start_index])\n",
    "                self.metrics[\"min_error_index\"][self.base_cnt-self.start_index] = int(best_fit_index)\n",
    "                self.best_factors = self.factors_all[self.base_cnt-self.start_index][best_fit_index]\n",
    "                self.best_weights = self.weights_all[self.base_cnt-self.start_index][best_fit_index]\n",
    "                for random_seed in range(self.trials):\n",
    "                    _log.info(\"Getting Similarity for Trial: {}\".format(random_seed))               \n",
    "                    self.cur_factors = self.factors_all[self.base_cnt-self.start_index][random_seed]\n",
    "                    self.cur_weights = self.weights_all[self.base_cnt-self.start_index][random_seed]\n",
    "                    self.metrics[\"stability\"][self.base_cnt-self.start_index].append(self.maxFactorSimilarity(self.cur_factors, self.cur_weights, self.best_factors, self.best_weights, self.base_cnt))   \n",
    "                self.cur_base = self.base_cnt                 \n",
    "                self.saveAttributes()\n",
    "            except:\n",
    "                # raise\n",
    "                continue\n",
    "                    \n",
    "\n",
    "    def maxFactorSimilarity(self, cur_factors, cur_weights, best_factors, best_weights, base_cnt):\n",
    "        \"\"\"\n",
    "        compute the max similarity to a given set of factors by permutations\n",
    "        based on equ.12 https://www.biorxiv.org/content/biorxiv/early/2017/10/30/211128.full.pdf\n",
    "        type cur_factors: array: the factors resulted from different runs\n",
    "        type cur_weights: array: the weights resulted from different runs\n",
    "        type best_factors: array: the factors with best fit\n",
    "        type best_weights: array: the weights with best fit\n",
    "        type base_cnt: int: the rank\n",
    "        rtype similarity: float: best similarity\n",
    "        \"\"\"\n",
    "        # from pprint import pprint\n",
    "        # import itertools\n",
    "        num_sample = 1000\n",
    "        # permuts = self.sc.parallelize(list(itertools.permutations(range(base_cnt)))).takeSample(False, num_sample, seed = 1)\n",
    "        random_seed = self.sc.parallelize(list(range(num_sample)))\n",
    "        \n",
    "\n",
    "\n",
    "        def computeEachSimilarity(each_seed, cur_factors, cur_weights, best_factors, best_weights):\n",
    "            each_permutation = list(np.random.RandomState(seed=each_seed).permutation(len(best_factors)))\n",
    "            # return np.mean([stats.spearmanr(cur_factors[list(each_permutation)[i]][j], best_factors[i][j])[0] for i in range(len(best_factors)) for j in range(len(best_factors[0]))])\n",
    "            similarity = 0.\n",
    "            for component_index in range(len(best_factors)):\n",
    "                rst = 1. - (abs(best_weights[component_index] - cur_weights[each_permutation[component_index]])) / max(best_weights[component_index], cur_weights[each_permutation[component_index]])\n",
    "                for factor_index in range(len(best_factors[0])):\n",
    "                    rst *= spatial.distance.cosine(cur_factors[each_permutation[component_index]][factor_index], best_factors[component_index][factor_index])\n",
    "                similarity += rst\n",
    "            similarity /= len(best_factors)\n",
    "\n",
    "            return similarity\n",
    "        \n",
    "        all_permutation_similarity = random_seed.map(lambda each_seed: computeEachSimilarity(each_seed, cur_factors, cur_weights, best_factors, best_weights)).collect()\n",
    "        similarity = max(all_permutation_similarity)\n",
    "        return similarity\n",
    "        \n",
    "            \n",
    "    def factorizeTensor(self, ones = True, random_seed = 1):\n",
    "        \"\"\"\n",
    "        factorize the tensor\n",
    "        type ones: boolean: whether use all ones as initialization\n",
    "        type random_seed: int: the random seed if not using ones\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Start factorization...\")\n",
    "        self.ntfInstance = ntf.NTF(self.cur_base, self.hist, parallelCalc=True, ones = ones, random_seed = random_seed)\n",
    "        self.ntfInstance.factorize(self.hist, showProgress=True)\n",
    "        self.ntfInstance.normalizeFactor()        \n",
    "\n",
    "        \n",
    "    def normalizeFactor(self):\n",
    "        \"\"\"\n",
    "        normalize the weights\n",
    "        \"\"\"        \n",
    "        self.ntfInstance.normalizedWeight = self.ntfInstance.weight / np.sum(self.ntfInstance.weight)            \n",
    "    \n",
    "    def getFactors(self):\n",
    "        \"\"\"\n",
    "        obtain the factors\n",
    "        \"\"\"        \n",
    "        \n",
    "        self.factors = self.ntfInstance.factor\n",
    "#         self.column = ['ZONE','PERIOD', 'TEAM']\n",
    "        self.data = [np.array([self.factors[i][j].tolist() for i in range(len(self.factors))]) for j in range(len(self.column))]\n",
    "        \n",
    "\n",
    "    def computeItemSimilarity(self):\n",
    "        \"\"\"\n",
    "        compute the pairwise item similarity\n",
    "        \"\"\"\n",
    "        import math\n",
    "        self.itemSimilarity = {}\n",
    "        for k in range(len(self.data)):\n",
    "            self.itemSimilarity[k] = {}\n",
    "            for i in range(len(self.data[k].T)):\n",
    "                self.itemSimilarity[k][self.labels[k][i]] = {}\n",
    "                for j in range(len(self.data[k].T)):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    dataSetI = self.data[k].T[i]\n",
    "                    dataSetII = self.data[k].T[j]\n",
    "                    # import pdb\n",
    "                    # pdb.set_trace()\n",
    "                    result = scipy.stats.spearmanr(dataSetI.T, dataSetII.T)\n",
    "                    # print(result)\n",
    "                    if not math.isnan(result.correlation):\n",
    "                        self.itemSimilarity[k][self.labels[k][i]][self.labels[k][j]] = result.correlation\n",
    "                    else:\n",
    "                        self.itemSimilarity[k][self.labels[k][i]][self.labels[k][j]] = 0\n",
    "\n",
    "                max_item = self.itemSimilarity[k][self.labels[k][i]][max(self.itemSimilarity[k][self.labels[k][i]], \n",
    "                                                                         key=self.itemSimilarity[k][self.labels[k][i]].get)]\n",
    "                min_item = self.itemSimilarity[k][self.labels[k][i]][min(self.itemSimilarity[k][self.labels[k][i]], \n",
    "                                                                         key=self.itemSimilarity[k][self.labels[k][i]].get)]\n",
    "                # normalize\n",
    "                if max_item != min_item:\n",
    "                    for j in self.itemSimilarity[k][self.labels[k][i]]:\n",
    "                        self.itemSimilarity[k][self.labels[k][i]][j] = (self.itemSimilarity[k][self.labels[k][i]][j] - min_item) / (max_item - min_item)\n",
    "\n",
    "    def computeEntropy(self):\n",
    "        \"\"\"\n",
    "        compute the entropy of each descriptor\n",
    "        \"\"\"\n",
    "        self.entropies = []\n",
    "        for j in range(len(self.factors[0])):\n",
    "            self.entropies.append([stats.entropy(self.factors[i][j]) for i in range(len(self.factors))])\n",
    "        self.max_entropy = np.max(self.entropies, axis = 1).tolist()\n",
    "        self.min_entropy = np.min(self.entropies, axis = 1).tolist()\n",
    "\n",
    "    def getMaxPatternForItem(self):\n",
    "        \"\"\"\n",
    "        compute the most relevant pattern for each item\n",
    "        \"\"\"\n",
    "        ## Get max pattern of each item\n",
    "        self.item_max_pattern = {}\n",
    "        for i in range(len(self.factors[0])):\n",
    "            self.item_max_pattern[i] = {}\n",
    "            for j in range(len(self.labels[i])):        \n",
    "                item_list_label = [self.factors[m][i][j] for m in range(len(self.factors))]        \n",
    "                self.item_max_pattern[i][self.labels[i][j]] = max(enumerate(item_list_label),key=lambda x: x[1])[0]\n",
    "        \n",
    "    def getMeanDistribution(self):\n",
    "        \"\"\"\n",
    "        compute the mean distribution of each descriptor\n",
    "        \"\"\"\n",
    "        data_mean = [np.mean([self.factors[i][j].tolist() for i in range(len(self.factors))],axis=0).tolist() for j in range(len(self.column))]\n",
    "        self.data_mean_descriptor = []\n",
    "        for m in range(len(data_mean)):\n",
    "            each_dict_descriptor = dict(zip(self.labels[m], data_mean[m]))\n",
    "            each_dict_descriptor['id'] = self.cur_base\n",
    "            self.data_mean_descriptor.append(each_dict_descriptor)\n",
    "        \n",
    "    def getEmbedding(self, rd_state = 3):\n",
    "        \"\"\"\n",
    "        use multiview tsne to embed the components to 2d plane\n",
    "        type rd_state: int: random state\n",
    "        \"\"\"\n",
    "        self.rd_state = rd_state\n",
    "        is_distance = [False] * len(self.data)\n",
    "        mvtsne_est = mvtsne.MvtSNE(k=2, perplexity = 10,random_state = self.rd_state, epoch = 3000)\n",
    "        mvtsne_est.fit(self.data, is_distance)\n",
    "        self.X_embedded = np.asarray(mvtsne_est.embedding_)        \n",
    "            \n",
    "            \n",
    "    def formatOutput(self):\n",
    "        self.data_output = {\"descriptors\": dict(zip(self.column, self.labels)),\n",
    "                            \"average\":self.data_mean_descriptor, \n",
    "                            \"itemSimilarity\":self.itemSimilarity,\n",
    "                            # \"metrics\":self.metrics,\n",
    "                            # \"item_max_pattern\": self.item_max_pattern,\n",
    "                            \"item_max_pattern\": '',\n",
    "                            \"start_index\":str(self.start_index),\n",
    "                            \"modes\": self.column}                \n",
    "        output = []\n",
    "        for i in range(len(self.factors)):\n",
    "            output_each = {}\n",
    "            output_each['id'] = i\n",
    "            output_each['factors'] = {}\n",
    "            output_each['dims'] = len(self.factors[i])\n",
    "            output_each['tsne_coord'] = {'x': self.X_embedded[i][0],'y':self.X_embedded[i][1]}\n",
    "            output_each['weight'] = self.ntfInstance.normalizedWeight[i]\n",
    "            output_each['max_tsne'] = np.max(self.X_embedded, axis = 0).tolist()\n",
    "            output_each['min_tsne'] = np.min(self.X_embedded, axis = 0).tolist()\n",
    "            for j in range(len(self.factors[i])):\n",
    "                a = self.factors[i][j]\n",
    "                output_each['factors'][j] = {}\n",
    "                output_each_factor = {}\n",
    "                output_each_factor['mode_id'] = j        \n",
    "                _dict = dict((self.labels[j][m], a[m]) for m in range(len(a)))\n",
    "                output_each_factor['max_item'] = max(_dict, key=_dict.get)\n",
    "                output_each_factor['min_item'] = min(_dict, key=_dict.get)\n",
    "                _dict['id'] = i\n",
    "                output_each_factor['values'] = _dict\n",
    "                output_each_factor['entropy'] = (self.entropies[j][i] - self.min_entropy[j]) / (self.max_entropy[j] - self.min_entropy[j])\n",
    "                output_each_factor['similarity'] = {}\n",
    "                for k in range(len(self.factors)):        \n",
    "                    if k == i:\n",
    "                        continue\n",
    "                    dataSetII = self.factors[k][j]\n",
    "                    dataSetI = self.factors[i][j]\n",
    "                    result = scipy.stats.spearmanr(dataSetI, dataSetII)[0]\n",
    "                    output_each_factor['similarity'][k] = result\n",
    "                dict_ = output_each_factor['similarity']\n",
    "                max_item = dict_[max(dict_, key=dict_.get)]\n",
    "                min_item = dict_[min(dict_, key=dict_.get)]\n",
    "                if max_item != min_item:\n",
    "                    for k in dict_:\n",
    "                        dict_[k] = (dict_[k] - min_item) / (max_item - min_item)\n",
    "                output_each_factor['similarity'] = dict_\n",
    "                output_each_factor['similarity']['average'] = sum(dict_.values())/len(dict_.values())  \n",
    "                output_each_factor['similarity']['max_idx'] = max(dict_, key=dict_.get)\n",
    "                output_each_factor['similarity']['min_idx'] = min(dict_, key=dict_.get)\n",
    "                output_each_factor['similarity'][i] = 1.0\n",
    "                output_each['factors'][j] = output_each_factor\n",
    "            output.append(output_each)\n",
    "\n",
    "        self.data_output[\"data\"] = output        \n",
    "            \n",
    "    def saveOutput(self):\n",
    "        \n",
    "        with open('/home/xidao/project/thesis/iFac/src/src/data/'+self.domain+'/factors_'+str(len(self.column))+'_'+str(self.cur_base)+'_sample_fit.json', 'w') as fp:\n",
    "            json.dump(self.data_output, fp)\n",
    "\n",
    "        with open('/home/xidao/project/thesis/iFac/src/src/data/'+self.domain+'/factors_'+str(len(self.column))+'_'+str(self.cur_base)+'_sample_fit_metrics.json', 'w') as fp:\n",
    "            json.dump(self.metrics, fp)         \n",
    "\n",
    "    def saveAttributes(self):\n",
    "        _log.info(\"Factorize Tensor\")   \n",
    "        self.factorizeTensor(ones = False, random_seed = iFac.metrics[\"min_error_index\"][self.cur_base-self.start_index])\n",
    "        _log.info(\"Get Factors\")          \n",
    "        self.normalizeFactor()\n",
    "        self.getFactors()\n",
    "        _log.info(\"Compute Item Similarity\")                    \n",
    "        self.computeItemSimilarity()\n",
    "        self.computeEntropy()\n",
    "        self.getMaxPatternForItem()\n",
    "        self.getMeanDistribution()\n",
    "        try:\n",
    "            self.getEmbedding()\n",
    "        except:\n",
    "            _log.info(\"running embedding again...\")\n",
    "            self.rd_state += 1\n",
    "            self.getEmbedding(rd_state = self.rd_state)\n",
    "        _log.info(\"Saving Output\")                              \n",
    "        self.formatOutput()\n",
    "        self.saveOutput()\n",
    "\n",
    "    def readFactorJSON(self, base_cnt=10, domain = \"\", ndims = 3):\n",
    "        self.base_cnt = base_cnt\n",
    "        self.domain = domain\n",
    "        self.ndims = ndims\n",
    "        file = \"../data/{}/factors_3_{}_sample_fit.json\".format(self.domain,self.ndims, self.base_cnt)\n",
    "        with open(file) as f:\n",
    "            self.data_output = json.load(f)\n",
    "\n",
    "    def readMetricJSON(self, base_cnt=10, domain = \"\", ndims = 3):\n",
    "        self.base_cnt = base_cnt\n",
    "        self.domain = domain\n",
    "        self.ndims = ndims\n",
    "        file = \"../data/{}_bk/factors_{}_{}_sample_fit_metrics.json\".format(self.domain, self.ndims, self.base_cnt)\n",
    "        with open(file) as f:\n",
    "            metrics = json.load(f)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "    def reEmbed(self, rd_state = 4):\n",
    "        self.getEmbedding(rd_state = rd_state)\n",
    "\n",
    "        for i in range(component_cnt):          \n",
    "            self.data_output['data'][i]['tsne_coord'] = {'x': self.X_embedded[i][0],'y':self.X_embedded[i][1]}\n",
    "            self.data_output['data'][i]['max_tsne'] = np.max(self.X_embedded, axis = 0).tolist()\n",
    "            self.data_output['data'][i]['min_tsne'] = np.min(self.X_embedded, axis = 0).tolist()\n",
    "\n",
    "        self.cur_base = component_cnt\n",
    "        self.column = self.data_output['modes']\n",
    "        self.saveOutput()\n",
    "\n",
    "\n",
    "def generateAll():\n",
    "    iFac = iFacData()\n",
    "    base = 30\n",
    "    iFac.start_index = 2\n",
    "    domain = \"policy\"   \n",
    "    nb_trials = 5\n",
    "\n",
    "    base = int(sys.argv[1])\n",
    "    iFac.start_index = int(sys.argv[2])\n",
    "    domain = str(sys.argv[3])\n",
    "\n",
    "    iFac.readData(domain = domain)\n",
    "    _log.info(\"Fitting Different Ranks up to {}\".format(base))\n",
    "    iFac.getFitForRanks(base, trials = nb_trials)\n",
    "\n",
    "def aggregateAll(start_index, end_index, domain = \"policy\"):\n",
    "    iFac = iFacData()\n",
    "    base = 30\n",
    "#     iFac.start_index = 2\n",
    "#     domain = \"policy\"   \n",
    "\n",
    "    iFac.start_index = start_index\n",
    "    iFac.end_index = end_index\n",
    "    domain = domain\n",
    "    measures = [\"error\", \"fit\", \"stability\", \"entropy\", \"normalized_entropy\", \"pctnonzeros\", \"gini\", \"theil\", \"min_error_index\"]        \n",
    "    start_metrics = iFac.readMetricJSON(base_cnt=iFac.start_index, domain = domain)\n",
    "    for i in range(iFac.start_index+1, iFac.end_index+1):\n",
    "        cur_metrics = iFac.readMetricJSON(base_cnt=i, domain = domain)\n",
    "        for m in measures:\n",
    "            cur_metrics[m] = [x for x in start_metrics[m] if x is not None] + [x for x in cur_metrics[m] if x is not None]        \n",
    "        with open('/home/xidao/project/thesis/iFac/src/src/data/'+domain+'/factors_3_'+str(i)+'_sample_fit_metrics.json', 'w') as fp:\n",
    "            json.dump(cur_metrics, fp)         \n",
    "\n",
    "def generateEmbedding():\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# #     generateAll()\n",
    "#     aggregateAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggregateAll(40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:84: DeprecationWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iFac = iFacData()\n",
    "base = 10\n",
    "# iFac.start_index = 10\n",
    "# iFac.end_index = 20\n",
    "domain = \"nbaplayer\"   \n",
    "iFac.readData(domain = domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getItemEmbedding(data, rd_state = 3):\n",
    "    \"\"\"\n",
    "    use multiview tsne to embed the components to 2d plane\n",
    "    type rd_state: int: random state\n",
    "    \"\"\"\n",
    "    \n",
    "    is_distance = [False] * 1\n",
    "    mvtsne_est = mvtsne.MvtSNE(k=2, perplexity = 10,random_state = rd_state, epoch = 3000)\n",
    "    mvtsne_est.fit([data], is_distance)\n",
    "    X_embedded = np.asarray(mvtsne_est.embedding_)\n",
    "    return X_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start factorization...\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "[20/100]\n",
      " None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "[40/100]\n",
      " None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "[60/100]\n",
      " None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "[80/100]\n",
      " None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "* None\n",
      "[100/100]\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "iFac.cur_base = 5\n",
    "iFac.factorizeTensor(ones = False, random_seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "iFac.normalizeFactor()\n",
    "iFac.getFactors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xidao/project/thesis/iFac/src/src/engine/multiview/mvtsne.py:278: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ((-2 * np.dot(ydata, ydata.T))[:, ] + sum_ydata[:]).T)\n"
     ]
    }
   ],
   "source": [
    "embeddings = getItemEmbedding(iFac.data[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnthonyDavis',\n",
       " 'ChrisPaul',\n",
       " 'DamianLillard',\n",
       " 'JamesHarden',\n",
       " 'JohnWall',\n",
       " 'KlayThompson',\n",
       " 'KyrieIrving',\n",
       " 'LaMarcusAldridge',\n",
       " 'LeBronJames',\n",
       " 'MontaEllis',\n",
       " 'NikolaVucevic',\n",
       " 'PauGasol',\n",
       " 'RussellWestbrook',\n",
       " 'StephenCurry',\n",
       " 'TyrekeEvans']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iFac.labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.31582051e+05,  1.40904085e+08],\n",
       "       [-4.36616355e+06,  2.65650479e+09],\n",
       "       [-4.36022007e+06,  2.65316766e+09],\n",
       "       [ 2.20478814e+07, -1.34159156e+10],\n",
       "       [-4.36560788e+06,  2.65518954e+09],\n",
       "       [-4.36526423e+06,  2.65672842e+09],\n",
       "       [-4.36429702e+06,  2.65525487e+09],\n",
       "       [-4.36613482e+06,  2.65609143e+09],\n",
       "       [-4.36334232e+06,  2.65600998e+09],\n",
       "       [-4.35929877e+06,  2.65311312e+09],\n",
       "       [-4.35931066e+06,  2.65401132e+09],\n",
       "       [ 2.20471730e+07, -1.34159156e+10],\n",
       "       [-2.31582319e+05,  1.40904095e+08],\n",
       "       [-4.36225067e+06,  2.65395190e+09]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 13 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 14 / 14\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] Iteration 25: error = 1.8577605, gradient norm = 0.0030199\n",
      "[t-SNE] Iteration 50: error = 1.7510022, gradient norm = 0.0026908\n",
      "[t-SNE] Iteration 75: error = 1.4105489, gradient norm = 0.0018343\n",
      "[t-SNE] Iteration 100: error = 1.3228570, gradient norm = 0.0016607\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.322857\n",
      "[t-SNE] Iteration 125: error = 1.1656243, gradient norm = 0.0013839\n",
      "[t-SNE] Iteration 150: error = 1.1143312, gradient norm = 0.0013017\n",
      "[t-SNE] Iteration 175: error = 1.1013039, gradient norm = 0.0012814\n",
      "[t-SNE] Iteration 200: error = 1.0977776, gradient norm = 0.0012760\n",
      "[t-SNE] Iteration 225: error = 1.0968055, gradient norm = 0.0012745\n",
      "[t-SNE] Iteration 250: error = 1.0965366, gradient norm = 0.0012741\n",
      "[t-SNE] Iteration 275: error = 1.0964618, gradient norm = 0.0012740\n",
      "[t-SNE] Iteration 300: error = 1.0964413, gradient norm = 0.0012739\n",
      "[t-SNE] Iteration 325: error = 1.0964355, gradient norm = 0.0012739\n",
      "[t-SNE] Iteration 325: error difference 0.000000. Finished.\n",
      "[t-SNE] Error after 325 iterations: 1.322857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "embeddings = TSNE(n_components=2, init='pca', verbose=2, perplexity= 20, random_state= 2).fit_transform(iFac.data[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -28.97663886,  -230.0191033 ],\n",
       "       [ -251.91947532,    -8.14492639],\n",
       "       [  -11.68831068,   179.19349836],\n",
       "       [  170.41079634,   231.5440651 ],\n",
       "       [  896.86877416,   920.81226355],\n",
       "       [  304.25544514,    23.2694574 ],\n",
       "       [ -195.09040003,   183.08697365],\n",
       "       [  -56.94180401,   -26.47995482],\n",
       "       [ -630.06479546, -1319.4970888 ],\n",
       "       [  117.48421304,    19.93860904],\n",
       "       [ -814.94454734,  -740.56498016],\n",
       "       [  707.63997015,  1340.60276891],\n",
       "       [  155.47057897,  -175.63281336],\n",
       "       [ -222.79189898,  -206.46679613]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/manifold/mds.py:396: UserWarning: The MDS API has changed. ``fit`` now constructs an dissimilarity matrix from data. To use a custom dissimilarity matrix, set ``dissimilarity='precomputed'``.\n",
      "  warnings.warn(\"The MDS API has changed. ``fit`` now constructs an\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embeddings = MDS(n_components=2)\n",
    "label_index = 2\n",
    "embeddings = embeddings.fit_transform(iFac.data[label_index].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJMAAARiCAYAAAAQvbY4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAQNv/AbBkSU9buOn4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f871669e048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_embedded_ = embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "xx = X_embedded_[:, 0]\n",
    "yy = X_embedded_[:, 1]\n",
    "\n",
    "colors = [\"blue\",\"red\"]\n",
    "# labes = [\"0\",\"1\"]\n",
    "# plot the 2D data points\n",
    "for i in range(len(iFac.labels[label_index])):    \n",
    "    ax.scatter(xx[i], yy[i], label=iFac.labels[label_index][i], s=20)\n",
    "    ax.annotate(iFac.labels[label_index][i], (xx[i], yy[i]))\n",
    "\n",
    "# ax.xaxis.set_major_formatter(NullFormatter())\n",
    "# ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "plt.legend(loc='best', scatterpoints=50, fontsize=10)\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.396882664913085,\n",
       "  2.3995887415675807,\n",
       "  2.39471412085592,\n",
       "  2.3888495546254576,\n",
       "  2.3838582928263317],\n",
       " [2.365725725380589,\n",
       "  2.368459571540182,\n",
       "  2.3686156901302047,\n",
       "  2.360013822992312,\n",
       "  2.3715420442638724],\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics['entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
